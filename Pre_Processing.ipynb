{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": "15",
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Pre-Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sgPyEocI-V7E",
        "3i_ZItx1-V7j",
        "WWELIXG_-V7y",
        "8jvuiw9i_mnC",
        "73QK0_Cf_qBP",
        "9XbLLC4NyAQR",
        "rP7bXo_XB0Zi",
        "U-70yAgUVxzE",
        "r99TFj4eDqD8",
        "6QKB2ccxJ_9L",
        "0skbA-VnKDOc",
        "OwG4T9TRMvaQ",
        "O5sARRHwM0Fl",
        "f_Koey_WSjiY",
        "cNUQxRghW70T",
        "1epAFPfIxWC-",
        "HHE64eMvfUg9",
        "ug4lJ29I_Kks",
        "fvtbnbXTXkJc",
        "Hv2O9HmcoSV7",
        "vne2Ej3koUES",
        "qmrAEErXwpDA",
        "uqmLae0uoXe7"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajesh-Khanna/NLP-Drug-review-classification/blob/master/Pre_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "sgPyEocI-V7E",
        "colab_type": "text"
      },
      "source": [
        "# <center>Download Dataset: <a href=\"https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29\">link</a></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-25T20:41:32.840057Z",
          "start_time": "2019-10-25T20:41:12.378654Z"
        },
        "hidden": true,
        "id": "aDpG-quh-V7P",
        "colab_type": "code",
        "outputId": "5a9149f6-7987-483b-cab5-b7ad50b5491e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!curl --output dataset.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
        "!unzip dataset.zip\n",
        "!rm dataset.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 40.9M  100 40.9M    0     0  12.1M      0  0:00:03  0:00:03 --:--:-- 12.1M\n",
            "Archive:  dataset.zip\n",
            "replace drugsComTest_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "replace drugsComTrain_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "3i_ZItx1-V7j",
        "colab_type": "text"
      },
      "source": [
        "# <center>Imports</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-01T17:14:06.407404Z",
          "start_time": "2019-11-01T17:13:55.502328Z"
        },
        "hidden": true,
        "id": "7JjL3KHy-V7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWELIXG_-V7y",
        "colab_type": "text"
      },
      "source": [
        "# <center>Processing to Tokens</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jvuiw9i_mnC",
        "colab_type": "text"
      },
      "source": [
        "## Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-01T17:14:11.207628Z",
          "start_time": "2019-11-01T17:14:06.420977Z"
        },
        "id": "E6MyuSwK-V71",
        "colab_type": "code",
        "outputId": "8d0fd92f-fe08-44e7-8389-23e595313368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import pandas as pd\n",
        "import html\n",
        "\n",
        "def load_dataset(filename):\n",
        "    df = pd.read_csv(filename, sep='\\t')\n",
        "    df.drop(df.columns[0], axis=1, inplace=True)\n",
        "    df.drop(['drugName', 'condition', 'date', 'usefulCount'], axis=1, inplace=True)\n",
        "    df['review'] = df['review'].apply(lambda x: x[1:-1])\n",
        "    df['review'] = df['review'].apply(html.unescape)\n",
        "    df['rating'] = df['rating'].astype('int64')\n",
        "    df['label'] = df['rating']\n",
        "    df.label[df['rating'] <= 4] = 0\n",
        "    df.label[(df['rating'] <= 6) & (df['rating'] >= 5)] = 1\n",
        "    df.label[df['rating'] >= 7] = 2\n",
        "    df.drop(['rating'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "df_train = load_dataset(\"drugsComTrain_raw.tsv\")\n",
        "df_test = load_dataset(\"drugsComTest_raw.tsv\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73QK0_Cf_qBP",
        "colab_type": "text"
      },
      "source": [
        "## Removing Stopwords and Tokenizing the reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6oXIq9p_VFV",
        "colab_type": "code",
        "outputId": "9fb8dde8-155c-4ea9-e4f3-49c1eb9a2c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "def func(row):\n",
        "    l = tokenizer.tokenize(row['review'])\n",
        "    s = [i.lower() for i in l if i not in stop_words]\n",
        "    return s\n",
        "df_train['processed'] = df_train.apply (lambda row: func(row), axis=1)\n",
        "df_test['processed'] = df_test.apply (lambda row: func(row), axis=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR2-z9ohpF1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4098fe22-836c-4643-ae36-eb82e899d324"
      },
      "source": [
        "df_train[1:6]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My son is halfway through his fourth week of I...</td>\n",
              "      <td>2</td>\n",
              "      <td>[my, son, halfway, fourth, week, intuniv, we, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I used to take another oral contraceptive, whi...</td>\n",
              "      <td>1</td>\n",
              "      <td>[i, used, take, another, oral, contraceptive, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is my first time using any form of birth ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[this, first, time, using, form, birth, contro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Suboxone has completely turned my life around....</td>\n",
              "      <td>2</td>\n",
              "      <td>[suboxone, completely, turned, life, around, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2nd day on 5mg started to work with rock hard ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[2nd, day, 5mg, started, work, rock, hard, ere...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                          processed\n",
              "1  My son is halfway through his fourth week of I...  ...  [my, son, halfway, fourth, week, intuniv, we, ...\n",
              "2  I used to take another oral contraceptive, whi...  ...  [i, used, take, another, oral, contraceptive, ...\n",
              "3  This is my first time using any form of birth ...  ...  [this, first, time, using, form, birth, contro...\n",
              "4  Suboxone has completely turned my life around....  ...  [suboxone, completely, turned, life, around, i...\n",
              "5  2nd day on 5mg started to work with rock hard ...  ...  [2nd, day, 5mg, started, work, rock, hard, ere...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XbLLC4NyAQR",
        "colab_type": "text"
      },
      "source": [
        "## Remove very large sentences if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwR9yQC3yDRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['processed_len'] = df_train.processed.apply(len)\n",
        "df_test['processed_len'] = df_test.processed.apply(len)\n",
        "df_train = df_train[df_train['processed_len'] <= 100].reset_index(drop=True)\n",
        "df_test = df_test[df_train['processed_len'] <= 100].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP7bXo_XB0Zi",
        "colab_type": "text"
      },
      "source": [
        "# <center>Embedding the Tokens</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-70yAgUVxzE",
        "colab_type": "text"
      },
      "source": [
        "## Glove embedings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r99TFj4eDqD8",
        "colab_type": "text"
      },
      "source": [
        "### Download Glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ux6hL9qRGZW",
        "colab_type": "code",
        "outputId": "b502ebcf-40cb-481a-ce16-0dfe66ec4de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget \"http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\"\n",
        "!unzip glove.6B.zip\n",
        "!rm glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-01 19:40:02--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.10MB/s    in 6m 29s  \n",
            "\n",
            "2019-11-01 19:46:31 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QKB2ccxJ_9L",
        "colab_type": "text"
      },
      "source": [
        "### Util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bl9-7Zsfm2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed(processed, w2v_dict, default_vec):\n",
        "    vectors = []\n",
        "    for w in processed:\n",
        "        if(w in w2v_dict):\n",
        "            vectors.append(w2v_dict[w])\n",
        "        else:\n",
        "            vectors.append(default_vec)\n",
        "    vectors = np.array(vectors)\n",
        "    return vectors\n",
        "\n",
        "def embed_using_glove(df, embed_dim=50):\n",
        "    # Load Glove embeddings.\n",
        "    GLOVE_FILE = 'glove.6B.' + str(embed_dim) + 'd.txt'\n",
        "    # Get number of vectors and hidden dimensions\n",
        "    with open(GLOVE_FILE, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            pass\n",
        "    n_vec = i + 1\n",
        "    hidden_dim = len(line.split(' ')) - 1\n",
        "    # Find the average of all embeddings to be assigned to tokens not in the embeddings.\n",
        "    # Create a word to vector dictionary for embedding.\n",
        "    avg_vec = np.zeros((hidden_dim), dtype=np.float32)\n",
        "    w2v_dict = {}\n",
        "    count = 0\n",
        "    with open(GLOVE_FILE, 'r') as f:\n",
        "        for line in f:\n",
        "            w2v_dict[line.split(' ')[:1][0]] = np.array([float(n) for n in line.split(' ')[1:]], dtype=np.float32)\n",
        "            avg_vec += np.array([float(n) for n in line.split(' ')[1:]], dtype=np.float32)\n",
        "            count+=1\n",
        "    avg_vec/=count\n",
        "\n",
        "    df['vectors'] = df.apply(lambda row: embed(row['processed'], w2v_dict, avg_vec), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0skbA-VnKDOc",
        "colab_type": "text"
      },
      "source": [
        "### Convert tokens in to Glove embeddings and save them to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwjVr2tLJmNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_using_glove(df_train, 50)\n",
        "df_train.to_pickle(\"train_glove_50.pckl\")\n",
        "embed_using_glove(df_test, 50)\n",
        "df_test.to_pickle(\"test_glove_50.pckl\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwG4T9TRMvaQ",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5sARRHwM0Fl",
        "colab_type": "text"
      },
      "source": [
        "### Download the Google word2vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24KezgZuRbwk",
        "colab_type": "code",
        "outputId": "faed13d4-5a11-405d-c869-975a375c7bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM -O word2vec.bin.gz\n",
        "!gunzip word2vec.bin.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/word2vec.bin.gz\n",
            "1.65GB [00:10, 162MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Koey_WSjiY",
        "colab_type": "text"
      },
      "source": [
        "### Load the word2vec embeddings into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Iiw7NcRSqjA",
        "colab_type": "code",
        "outputId": "060500d2-0bfe-4a4d-8e3f-137e8420c447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "    from gensim.models import KeyedVectors\n",
        "    \n",
        "    w2v_model = KeyedVectors.load_word2vec_format('word2vec.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNUQxRghW70T",
        "colab_type": "text"
      },
      "source": [
        "### Util funcitons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyQQerUzW68n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed(processed, w2v_dict, default_vec):\n",
        "    vectors = []\n",
        "    for w in processed:\n",
        "        if(w in w2v_dict):\n",
        "            vectors.append(w2v_dict[w])\n",
        "        else:\n",
        "            vectors.append(default_vec)\n",
        "    vectors = np.array(vectors)\n",
        "    return vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1epAFPfIxWC-"
      },
      "source": [
        "### Get smaller versions of train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aqw1UeLhxWDR",
        "colab": {}
      },
      "source": [
        "df_train_w2v = df_train.sample(n=int(df_train.shape[0]/6)).reset_index(drop=True)\n",
        "df_test_w2v = df_test.sample(n=int(df_test.shape[0]/6)).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHE64eMvfUg9",
        "colab_type": "text"
      },
      "source": [
        "### Convert the tokens into Word2Vec embeddings and save them to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUw50_VeUU5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_avg = np.average(w2v_model.vectors, axis=0)\n",
        "df_train_w2v['vectors'] = df_train_w2v.apply(lambda row: embed(row['processed'], w2v_model, w2v_avg), axis=1)\n",
        "df_test_w2v['vectors'] = df_test_w2v.apply(lambda row: embed(row['processed'], w2v_model, w2v_avg), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1eafb9bf-9965-415c-c7fd-707b1434d5a3",
        "id": "LH6rJMjryvzC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "df_train_w2v.memory_usage(deep=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index                   128\n",
              "review             13565982\n",
              "label                214200\n",
              "processed          13183544\n",
              "processed_len        214200\n",
              "vectors          1602832200\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug4lJ29I_Kks",
        "colab_type": "text"
      },
      "source": [
        "## Elmo embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvtbnbXTXkJc",
        "colab_type": "text"
      },
      "source": [
        "### Install allennlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX4DiLtJXnxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv2O9HmcoSV7",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhYYiddBjbfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vne2Ej3koUES",
        "colab_type": "text"
      },
      "source": [
        "### Util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhMhSy3xXoeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_elmo_embeddings(elmo, documents, max_sentences = 1000):\n",
        "    num_sentences = min(max_sentences, len(documents)) if max_sentences > 0 else len(documents)\n",
        "    print(\"\\n\\n:: Lookup of \" + str(num_sentences) + \" ELMo representations. This takes a while ::\")\n",
        "    embeddings = []\n",
        "    tokens = documents['processed'].to_numpy()\n",
        "    \n",
        "    documentIdx = 0\n",
        "    for elmo_embedding in elmo.embed_sentences(tokens):  \n",
        "        document = documents.iloc[documentIdx]\n",
        "        # Average the 3 layers returned from ELMo\n",
        "        avg_elmo_embedding = np.average(elmo_embedding, axis=0)             \n",
        "        embeddings.append(avg_elmo_embedding)        \n",
        "        \n",
        "        # Some progress info\n",
        "        documentIdx += 1\n",
        "        percent = 100.0 * documentIdx / num_sentences\n",
        "        line = '[{0}{1}]'.format('=' * int(percent / 2), ' ' * (50 - int(percent / 2)))\n",
        "        status = '\\r{0:3.0f}%{1} {2:3d}/{3:3d} sentences'\n",
        "        sys.stdout.write(status.format(percent, line, documentIdx, num_sentences))\n",
        "        \n",
        "        if max_sentences > 0 and documentIdx >= max_sentences:\n",
        "            break\n",
        "            \n",
        "    return embeddings\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qmrAEErXwpDA"
      },
      "source": [
        "### Get smaller versions of train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dzCGQ9MZN7u",
        "colab_type": "code",
        "outputId": "3ba89d00-9846-4774-dcda-c0b331515ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "df_train_elmo = df_train.sample(n=int(df_train.shape[0]/20)).reset_index(drop=True)\n",
        "df_test_elmo = df_test.sample(n=int(df_test.shape[0]/20)).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqmLae0uoXe7",
        "colab_type": "text"
      },
      "source": [
        "### Get ELMo embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2frbjy9yokoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = ElmoEmbedder(cuda_device=0) #Set cuda_device to the ID of your GPU if you have one\n",
        "df_train_elmo['elmo_embeddings'] = create_elmo_embeddings(elmo, df_train_elmo, -1)\n",
        "df_test_elmo['elmo_embeddings'] = create_elmo_embeddings(elmo, df_test_elmo, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}